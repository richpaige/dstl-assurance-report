\documentclass{llncs}

\usepackage{graphicx}
\usepackage{url}
\usepackage{courier}
\usepackage{listings}
\usepackage{enumerate}


\input{listings.tex}


\begin{document}


\title{Technical Obsolescence Management Strategies for Safety-Related Software for Airborne Systems -- Assurance Report}

\author{Richard F. Paige\inst{1}, Simos Gerasimou\inst{1} and Dimitris Kolovos\inst{1}}

\institute{
Department of Computer Science, University of York, UK.\\
\email{[richard.paige,simos.gerasimou,dimitris.kolovos]\_at\_york.ac.uk}
}
\maketitle

\begin{abstract}
This report briefly summarises the technical challenges associated with certification (and re-certification)
of software after a particular obsolescence management strategy -- described in a companion report -- has
been carried out. In particular, it firstly considers the types of evidence that can
be produced by the management strategy. Secondly, it considers the DO-178B objectives and analyses where specific objectives
may need to be reconsidered in order to achieve re-certification. In this manner it aims to demonstrate where
re-certification effort may need to be prioritised.Finally, it briefly comments on two issues: qualification of tools that support
the management strategy, and automatic generation of certification cases, which may help to reduce the amount of effort 
required in supporting re-certification.
\end{abstract}

\section{Introduction}
Complex software systems deployed in safety-critical and business-critical 
application domains (e.g., avionics, defence, healthcare) are meant to provide 
service for decades. Although many of these systems withstand technological 
evolution and infrequently undergo substantial changes, they will likely face 
software obsolescence problems during their lifetime. 
Resolving these obsolescence problems is an expensive, time-consuming and 
labour intensive process. The costs

In this project, we explore reactive strategies for managing software 
obsolescence in safety-related software for airborne 
systems~\cite{ProjectResponse}. More specifically, we 
investigate the extent to which \textit{software modernisation} -- i.e., 
approaches that involve changes to the system 
structure, adaptation to more advanced technologies, and functionality 
enhancement -- can mitigate the problem of software obsolescence and extend the 
life, performance and reliability of existing systems. We adopt an 
experimental-based approach and use a set of demonstrators to explore different 
facets of software modernisation, 
including reverse engineering, program understanding, demonstration of 
functional equivalence of 
migrated code, change in hardware platform, maintenance of performance, and 
preservation of Design Assurance Levels (DAL).

In this report we focus on certification and assurance issues, specifically: if the obsolescence management strategy
presented in the companion report is applied to a system at DAL-C, what are the certification issues associated with
the migrated software? In particular, what effort will be required to re-certify the software system, and what evidence
can the strategy provide in order to support re-certification?

The emphasis in this 11-month project sponsored by DSTL has been on building and evaluating a technical solution to
software obsolescence on several case studies; assurance and certification has been a secondary concern. As such, this
report is primarily speculative. It is structured as follows. Firstly, we describe the evidence that is produced by the 
obsolescence strategy and technical solution that is relevant to certification and recertification. We also briefly describe
the toolchain that has been developed to support the obsolescence strategy, so that the report is moderately self-contained
and hence easier to follow. Next, we analyse the DO-178B objectives and summarise which specific objectives \textit{must} and
\textit{could} be reconsidered as a result of applying the strategy. Finally, we comment on two issues: that of tool qualification
(and the challenges that will arise in qualifying the toolchain developed within this project), and of automatically generating 
assurance/safety cases from the engineering artefacts that are provided as input to the obsolescence strategy.

\section{Background and Evidence}
In this section, we briefly describe the technical solution that has been developed to help support an obsolescence management
strategy. The solution and the obsolescence management strategy is described in more detail in the accompanying report \cite{Gerasimou2017}. 
We also briefly describe the evidence that is produced by following the strategy and using the technical approach.

\subsection{Technical approach summary}
Technological obsolescence problems
include end-of-support of a crucial software component (which is part of a 
software system) that enforces adaptation to more advanced technologies, and 
the 
need to transform parts of a software system developed in a ``legacy'' 
programming language to a modern programming language (e.g., from Ada to 
C/C++). 
A common, but challenging, functional obsolescence problem  of interest 
involves the migration of an entire software system from a legacy hardware 
platform to a modern, more powerful platform.

Resolving these software obsolescence problems is typically a manual and laborious process. We have explored techniques to enable the partial 
automation of reactive mitigation strategies, targeting mainly C/C++ software 
systems. In particular, we proposed a combination of code analysis, code-based 
transformation and verification/validation techniques for the 
\textit{modernisation} of software systems.
Figure~\ref{fig:approach} depicts an overview of the proposed approach to 
software modernisation. 

\begin{figure}[htbp]
	\vspace*{-2em}
	\centering
	\includegraphics[width=.9\linewidth]{architecture.pdf}
	
	\caption{High-level software modernisation approach.}
	\label{fig:approach}
	
	\vspace*{-2em}
\end{figure}

Through analysing the source code of the software system under consideration, 
we would gain insight into the architecture of the system, including 
interconnections between software modules and dependencies with 
external libraries and components. Furthermore, this code analysis will provide 
useful information on how to best address the obsolescence issues and 
re-architect the software, if needed.

The approach illustrated in Figure~\ref{fig:approach} is based on the use of transformation technology.
Two types of transformations have been used to support rehosting: extraction 
transformations (to ``pull''Äù abstract specifications from legacy code) and text 
generators, based on templates. The transformations have been implemented using Epsilon, the rich C/C++ parsing and analysis 
infrastructure provided by the Eclipse CDT project, and ANTLR/Xtext to support 
additional languages 
such as Ada. The former for implementing the templates, the latter to extract 
abstract specifications from legacy code, in a form suitable for re-engineering 
and amenable to application of the templates. 
The transformation chain will automatically generate traceability 
information in a standard format (e.g., XML-based). Such information will be potentially useful as
evidence that the rehosted/migrated application would be supportive of Software Level C.
In particular, it could used to demonstrate a partial validity argument, 
i.e., that all statements and expressions in the legacy program are transformed 
to statements and expressions in the retargeted program. 

\subsection{Evidence}
The obsolescence management strategy makes use of a number of techniques to support software migration and rehosting.
These techniques are underpinned by a number of engineering artefacts that can either be used directly as evidence in assurance, or
can be used to \textit{generate} evidence that can be used to support assurance, of the migrated or rehosted software system. 
We are assuming that we are migrating a system that has already undergone some level of certification or assurance,
e.g., against DO-178B or similar standards, to DAL-C or similar. As such, some assurance evidence already exists.

The sources of evidence available to or generated by the obsolescence management strategy and technical approach are as follows.

\begin{itemize}
\item \textit{Tests}: test cases and test evidence will have been produced for the original certification and assurance. Migration and rehosting
is designed to ensure that the migrated software system is behaviourally equivalent (modulo behavioural differences in the hardware platform).
As such, the migrated and rehosted system should satisfy the original test cases.

\item \textit{Traceability}: the technical approach we have developed generates (as a side-effect) traceability information between the original
source program and the target program. In this way, information capturing how source statements have been replaced with target statements has
been captured. This information can be externalised and used to support impact analysis, which in turn will provide information to safety engineers as
to (a) which parts of the software system have changed; (b) which parts have not changed; and (c) where they may need to concentrate their efforts
in re-certifying. Note that traceability information is \textit{static} and \textit{syntactic:} it captures the fact that program statements have been 
transformed into new program statements, but says nothing about the meaning of the transformation.

\item \textit{Transformations:} the rehosting/migration technical approach makes use of transformations and text generation algorithms, which have
been tested and can be further audited and reviewed, in much the same way as a compiler can be tested and reviewed and ultimately qualified (though in Section~\ref{sec:future}
we briefly discuss some of the challenges of qualifying migration tool chains like the one we have developed).
\end{itemize}

In the next section we briefly discuss the impact of migration on relevant safety standards -- particularly DO-178B -- and analyse the effect of migrating
a software system using the technical approach on any previously existing safety argument and safety process.

\section{Certification and DO-178B Objectives}
In this section we discuss issues associated with migrating a software application where the original system has been certified with respect to DO-178B,
which is an appropriate standard to be used in the development of a legacy airborne system. In particular, what we wish to investigate is the \textit{impact}
of migration on an accomplishment summary. Recall that DO-178B identifies a set of software activities that can take place within the context of a broader 
engineering process, and requires an accomplishment summary \cite{DO178B} as part of the certification deliverables. The accomplishment summary is a 
document that demonstrates compliance of a system with the plan for software aspects of certification. The accomplishment summary in
DO-178B requires the following to be addressed:

\begin{enumerate}[(a)]
\item System overview
\item Software overview
\item Certification considerations
\item Software characteristics
\item Software life cycle 
\item Software life cycle data
\item Additional considerations
\item Software identification
\item Change history
\item Software status
\item Compliance statement
\end{enumerate}

The primary safety argument underlies the software life cycle data. This is clear in Annex A, which provides tables of objectives for each of ten areas. The tables are:
\begin{enumerate}
\item Software Planning Process
\item Software Development Process
\item Verification of Outputs of Software Requirements Process
\item Verification of Outputs of Software Design Process
\item Verification of Outputs of Software Coding and Integration Processes
\item Testing of Outputs of Integration Process 
\item Verification of Verification Process Results
\item Software Configuration Management Process
\item Software Quality Assurance Process
\item Certification Liaison Process
\end{enumerate}

Several of the tables map directly to the accomplishment summary, e.g., Table 8 relates to point h, software identification, and Table 10 relates to point c. The majority of tables, i.e. 3-7, are primarily providing support for point f, software life cycle data, in the accomplishment summary. 

So if an accomplishment summary has been produced for a legacy system, and the software application has been migrated, then the accomplishment summary will no longer be valid and accurate for the migrated application. What parts of the accomplishment summary -- i.e., the Objective tables in Annex A -- will either be invalidated (and hence require full work) or partially invalidated? We briefly outline the results of our initial analysis. We attempt to indicate if Objectives are \textit{directly} impacted by the application of the migration technology and strategy (and hence substantial work will be required to rebuild an accomplishment summary), and if Objectives are \textit{indirectly} impacted (in which case any rework will hopefully be minor). The assumptions are:
\begin{itemize}
\item the original system has been developed according to DO-178B\footnote{Given that we are migrating legacy aerospace applications, at least in theory, this seems a reasonable assumption. In future, consideration of DO-178C will be necessary. It would also be interesting to consider technical migration of accomplishment summaries from DO-178B to DO-178C, but this is a research project in and of itself.};
\item the software has been migrated using our technical approach, outlined in the previous section;
\item test cases from the original system are available (and these test cases are automated and executable).
\end{itemize}
We are only able to produce a preliminary assessment of impact of migration against the DO-178B objectives, given the time and resource available to us in the project. 

\subsection{Table A-1: Software Planning Process}
Our view is that this table is only indirectly (and lightly) impacted by the application of the migration strategy and approach. There will be one-off costs associated with documenting the new development process associated with the migrated application (which is a combination of the original development process and the application of the obsolescence strategy), setting up the process, explaining it to the certification authority, etc. There may also be process improvement issues as developers become more experienced with the migration approach and can see ways to improve it or extend it. 

\subsection{Table A-2: Software Development Processes}
Our view is that this table is indirectly impacted by the application of the migration strategy. We are assuming that the requirements have not changed, and that an architecture is still developed. The most signfiicant impact should be with objective A-2-6 (Source code is developed) -- the migration approach produces new source code, but it is generated automatically rather than manually by an engineer. It may be that documenting the process by which source code is produced is sufficient to convince a certifying authority.

\subsection{Table A-3: Verification of Outputs of Software Requirements Process}
This table is indirectly impacted, but it is here that we start to see a greater impact from migration: the impact will be mitigated by reuse of tests to demonstrate that algorithms remain accurate. However, migration to a new hardware platform may affect algorithm accuracy, and so it is questionable whether, in all circumstances, that reused acceptance, integration and system tests will be sufficient to fully demonstrate that the compliance and consistency objectives have been met. If, however, reuse of tests is not possible for whatever reason, this objective will be directly and significantly impacted and all objectives in the table may need to be re-established.

\subsection{Table A-4: Verification of Outputs of Software Design Process}
This table may be \textit{directly} impacted, depending on the form of migration: in the case where migration to a new hardware platform, or a new programming language or operating system is involved, there will be direct impact. 

There are similar concerns about algorithm accuracy (A-4-7) as discussed in the previous subsection. The objectives specific to software architecture (i.e., A-4-8 through A-4-13) are directly impacted due to migration, especially A-4-10 (e.g., if the new hardware platform is significantly different to the original, such as in the case of migrating from single core to multicore). In general, if the software architecture from the original system remains unchanged (i.e., behaviourally equivalent components and interfaces) then A-4-8 through A-4-13 (excepting A-4-10) should hold. New evidence will need to be produced to demonstrate that the migrated software architecture is compatible with the target architecture.

\subsection{Table A-5: Verification of Outputs of Software Coding and Integration Processes}
\label{sec:a-5}
This table may be \textit{directly} impacted, particularly because this requires demonstration that source code complies with low-level requirements, and new source code has been produced. At worst, this will require a fresh argument to support A-5-1, to show that the migrated code complies with low-level requirements. There may be opportunities to exploit \textit{model weaving} to reduce the effort in this: since we have (from the previous summary) evidence that the original source code complies with requirements, and we have traceability (supplied by the migration strategy) from original to new source code, we envision a process where this evidence and traceability information is woven together. At the very least this could indicate which parts of the original requirements/source code relationship have changed and require re-certification. A similar approach could be used for A-5-5. 

Another issue to consider is independence: if original code is migrated, is the independence (required for A-5-1) lost? Does anything new have to be done to re-establish independence when assuring the migrated code?

%% This one is tricky, especially A-5-5 traceability of code to low-level requirements
%% Also, what about the independence argument for A-5-1 and A-5-2; if you migrate the code does that invalidate the independence from the
%% original, if you are at SW Level A or B? 

\subsection{Table A-6: Testing of Outputs of Integration Process}
This table is \textit{directly} impacted by application of the migration strategy, largely because it involves object code that must be produced from source code. As such, objectives A-6-1 through A-6-5 have to be carried out again once new object code has been produced from the new source code. Are there opportunities for reuse of the original safety argument? Perhaps -- the main difficulty will be in producing evidence to show how new object code relates to the original object code (the migration strategy that we have developed generates traceability information only for rehosting of source code; an instrumented compiler would be needed to generate traceability information for object code). If such traceability information could be provided, then a model weaving approach may potentially be applied, similar to what was discussed in Section~\ref{sec:a-5}.

\subsection{Table A-7: Verification of Verification Process Results}
This table will be \textit{directly} impacted by migration assuming that test cases (and test procedures etc) from the original application are available. However the direct impact may not be as significant as in some of the previous tables. Assuming that test cases and procedures are reused, then we do not expect objectives A-7-1 through A-7-4 to be affected. However objectives A-7-4 through A-7-8 may have to be re-established as it may be the case that the source code structures have changed as a result of rehosting (e.g., introduction of new control structures due to introduction of a new library or API), and previous MC/DC evidence is no longer valid. However, if it possible to evidence that the source code structures have not changed as a result of migration (which may be the case if it is a simple API replacement), then the previous evidence may remain valid.

\subsection{Table A-8: Software Configuration Management Process}
This table will be \textit{indirectly} affected. The issue here is whether the technical solution to software migration should be supported by the configuration management process. Effectively, does the software life cycle \textit{include} the technical software migration phase, or is this phase assumed to be out of scope? In our view it should be consider in-scope as some of the evidence used to support re-certification (traceability data) is produced by the technical solution. This traceability data must be considered in baselining activities under A-8-2. Additionally, new configuration items related to the components of the technical solution (grammars, parsers, templates, transformations) should also be considered in A-8-1. It may be that the other objectives can remain unchanged.

\subsection{Table A-9: Software Quality Assurance Process}
This table is arguably \textit{indirectly} impacted, largely because the software development and integral processes have been modified as a result of using the technical migration solution: new code is produced by applying the technical solution, and it is automatically integrated with existing code that has not changed. These processes need to be shown to comply with software plans and standards. It is not immediately clear if \textit{new} standards need to be considered with respect to the technical solution -- for example, standards for representing evidence produced by the technical solution. It may, for example, be necessary and useful to ensure that traceability evidence generated by the technical solution is compliant with suitable standards -- e.g., the OMG's Structured Assurance Case Metamodel -- even if these have not yet seen widespread use in safety critical projects.

\subsection{Table A-10: Certification Liaison Process}
This table is of course \textit{directly} impacted across all objectives as there will be changes made to the production of an accomplishment summary for the migrated code, and the certifying authority will need to be informed and will need to buy-in to the new processes. Given that certifying authorities are increasingly aware of DO-178C (and, for example, the model-based design annexe, which is aimed at supporting lifecycles with some similarity to our technical solution), this may be less problematic and challenging today than it was several years ago.


\section{The Future: Tool Qualification and Assurance Case Generation}
In this section we briefly explore two issues that have not been considered at all in this project -- tool qualification and assurance case generation -- and posit on some of the difficulties associated with their use in the future.

\subsection{Tool Qualification}
The technical solution that has been produced in this project automates otherwise manual processes (e.g., API rewriting). As such, and according to SC-205/WG-71, assurance should be obtained that the technical solution is at least as dependable as the manual approach. 

DO-178C defines three criteria that determine the applicable tool qualification level (TQL); one is relevant to the technical solution that has been produced in this project:

\begin{quotation}
\textbf{Criteria 1:} A tool whose output is part of the airborne software and thus could insert an error.
\end{quotation}
Criteria 2 relates to verification processes (which are not considered by the technical solution), whereas Criteria 3 relates to failure of detection of errors. We do not believe that Criteria 3 is relevant as it is focused on verification tools. As such, Criteria 1 is relevant to the technical solution. If the qualification criterion for the software application being rehosted is Level C, then the applicable TQL is level 3: the replacement of DO-178B development tool for each software level.

With respect to DO-330/ED-215, there are a number of considerations related to tool qualification for the technical solution. 

Firstly, the operational environment for the technical solution needs to be established. This needs to meet specific objectives related to installing the technical solution in the appropriate environment, showing that the tool requirements are compatible with the operational environment, etc. It should be observed that the technical solution has been developed in an iterative and incremental manner, in close collaboration with DSTL, and as such a rigorous requirements specification for the tool has not been produced. As such, additional future work will need to be carried out on this. This should likely include the \textit{Tool Operational Requirements (TOR)} (i.e., Section~10.3.1 of DO-330). 

The TOR for the technical solution that has been produced is complicated, in part because the tool has interfaces with other tools, particularly Eclipse, which has a plug-in architecture. Eclipse is a very substantial piece of software that can be customised for different purposes. This project has relied on Eclipse CDT (a set of tools for development of C/C++, including parsers) and Eclipse Epsilon (a set of tools for code generation and transformation). Capturing the tool functions and technical features will be challenging because of the generality of Eclipse. As well, capturing abnormal activation modes for the technical solution will be challenging as some of these will also depend on activation modes for Eclipse and for its sub-projects. We envision a larger research program to assess the challenges and difficulties of tool qualification within the Eclipse ecosystem, and suggest collaboration with Polarsys\footnote{\url{www.polarsys.org}} to support this.

\section{Conclusions}

\bibliographystyle{abbrv}
\bibliography{bibliography}
\renewcommand{\baselinestretch}{1.0}


\end{document}